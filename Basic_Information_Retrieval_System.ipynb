    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "class InformationRetrievalSystem:\n",
        "    def __init__(self):\n",
        "        self.dictionary = {}\n",
        "        self.documents = []\n",
        "        self.inverted_index = defaultdict(set)\n",
        "        self.doc_id_counter = 0\n",
        "        self.doc_id_to_filename = {}\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess_text(self, content):\n",
        "        content = content.lower()\n",
        "        content = re.sub(r'http[s]?://\\S+', '', content)\n",
        "        content = re.sub(r'[^\\w\\s]', '', content)\n",
        "        content = re.sub(r'\\d+', '', content)\n",
        "        words = word_tokenize(content)\n",
        "        words = [word for word in words if word not in self.stop_words]\n",
        "        words = [self.lemmatizer.lemmatize(word) for word in words]\n",
        "        return words\n",
        "\n",
        "    def add_document(self, content, filename):\n",
        "        words = self.preprocess_text(content)\n",
        "        self.documents.append(content)\n",
        "        self.doc_id_to_filename[self.doc_id_counter] = filename\n",
        "        for word in words:\n",
        "            if word not in self.dictionary:\n",
        "                self.dictionary[word] = len(self.dictionary)\n",
        "            self.inverted_index[self.dictionary[word]].add(self.doc_id_counter)\n",
        "        self.doc_id_counter += 1\n",
        "\n",
        "    def add_documents_from_directory(self, directory):\n",
        "        for filename in os.listdir(directory):\n",
        "            if filename.endswith('.txt'):\n",
        "                with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "                    content = file.read()\n",
        "                    self.add_document(content, filename)\n",
        "\n",
        "    def boolean_and(self, query):\n",
        "        words = self.preprocess_text(query)\n",
        "        result_set = None\n",
        "        for word in words:\n",
        "            word_id = self.dictionary.get(word, -1)\n",
        "            if word_id == -1:\n",
        "                return set()\n",
        "            word_set = self.inverted_index[word_id]\n",
        "            if result_set is None:\n",
        "                result_set = word_set\n",
        "            else:\n",
        "                result_set &= word_set\n",
        "        return result_set\n",
        "\n",
        "    def get_filename(self, doc_ids):\n",
        "        return [self.doc_id_to_filename[doc_id] for doc_id in doc_ids]\n",
        "\n",
        "\n",
        "ir_system = InformationRetrievalSystem()\n",
        "ir_system.add_documents_from_directory('/content/docs')\n",
        "\n",
        "query1 = \"advice Monimia\"\n",
        "query2 = \"Sentimental Travels Permission\"\n",
        "\n",
        "result1 = ir_system.boolean_and(query1)\n",
        "result2 = ir_system.boolean_and(query2)\n",
        "\n",
        "print(f\"'{query1}' document id is :\", result1)\n",
        "print(f\"'{query1}' is in document:\", ir_system.get_filename(result1))\n",
        "print('\\n')\n",
        "print(f\"'{query2}' document id is :\", result2)\n",
        "print(f\"'{query2}' is in document:\", ir_system.get_filename(result2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8xbod0WMEEs",
        "outputId": "59d1dd62-fdc9-4689-d130-c87ccfa9b868"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'advice Monimia' document id is : {1, 9}\n",
            "'advice Monimia' is in document: ['doc6.txt', 'doc7.txt']\n",
            "\n",
            "\n",
            "'Sentimental Travels Permission' document id is : {0, 2, 3, 4, 5, 7, 9}\n",
            "'Sentimental Travels Permission' is in document: ['doc4.txt', 'doc8.txt', 'doc3.txt', 'doc9.txt', 'doc10.txt', 'doc5.txt', 'doc7.txt']\n"
          ]
        }
      ]
    }
  ]
}
